data: /projects/0/einf2071/data/CIFAR100/
dataset: cifar100
zeroeth_gpu: 0
gpu: 1
iterations: 30
n_classes: 100
n_doe: 300
n_epochs: 25
n_warmup_epochs: 0
n_gpus: 2
n_iter: 300
n_surrogate_evals: 10000
n_workers: 8
path_logs: /projects/0/einf2071/nsganetv2/logs/
predictor: rbf_ensemble_per_ensemble_member_cascade_combo
random_seed: 1723
seed_offset: 0
sec_obj: flops
supernet_path: 
  - data/alphanet_pretrained.pth.tar
  - data/ofa/supernet_w1.2
  - data/ofa/supernet_w1.0
  - data/attentive_nas_pretrained.pth.tar
  - data/ofa_proxyless_d234_e346_k357_w1.3
alphabet: 
  - full_alphanet_cascade5
  - full_nat_w12_cascade5
  - full_nat_w10_cascade5
  - full_alphanet_cascade5
  - full_nat_proxyless_cascade5
ensemble_ss_names:
  - alphanet
  - ofa
  - ofa
  - alphanet
  - proxyless
search_space: ensemble
search_goal: cascade
experiment_name: cifar100_r0_5nets
train_continuous: true
trn_batch_size: 96
use_diversity_objective: false
vld_batch_size: 150
vld_size: 10000
cutout_size: 0
n_runs: 2
dont_check_duplicates: true
add_archive_to_candidates: true
sample_configs_to_train: false
init_with_nd_front: false
if_debug_run: false
if_create_unique_gpu_lock: false
gomea_exe: /home/chebykin/MO_GOMEA/exes/MO_GOMEA_default_ndinit_lb_lessoutput_intsolution_dontcountcache_usepythonpath
if_single_gpu_mode: true
store_checkpoint_freq: 1
use_gradient_checkpointing: false
if_amp: true
lr_schedule_type: cosine
resize_scale: 0.08
if_cutmix: true
post_swa: 20
if_store: true
git_hash: f4dcb320cdeec7258ed6105d432d39afb2b7aad0
algo_mods_all:
  - search_algo: mo-gomea
    subset_selector: reference